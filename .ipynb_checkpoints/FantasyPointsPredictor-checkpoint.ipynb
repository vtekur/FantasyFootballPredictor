{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatPlayerName(name):\n",
    "    try:\n",
    "        starIndex = name.index(\"*\")\n",
    "    except ValueError:\n",
    "        starIndex = sys.maxsize\n",
    "    try:\n",
    "        slashIndex = name.index(\"\\\\\")\n",
    "    except ValueError:\n",
    "        slashIndex = sys.maxsize\n",
    "    return name[:min(starIndex, slashIndex)]\n",
    "def preprocessWR(data):\n",
    "    data.columns = data.iloc[0]\n",
    "    data = data.drop(columns = [\"Passing\", \"Rushing\", \"Scoring\", \"Fumbles\"])\n",
    "    data = data.drop([0])\n",
    "    data.columns = data.iloc[0]\n",
    "    data = data.drop([1])\n",
    "    data = data[data.FantPos == \"WR\"]\n",
    "    data = data.drop(columns = [\"Rk\", \"GS\", \"FantPos\", \"Y/R\", \"PPR\", \"DKPt\", \"VBD\", \"FDPt\", \"PosRank\", \"OvRank\", \"Tm\"])\n",
    "    data = data[data.G >= 12]\n",
    "    data = data.dropna()\n",
    "    data[\"Player\"] = data[\"Player\"].map(formatPlayerName)\n",
    "    data = data.set_index(\"Player\")\n",
    "    return data\n",
    "def createDataset(years):\n",
    "    yearToOriginalData = {}\n",
    "    finalData = pd.DataFrame()\n",
    "    for index, year in enumerate(years): \n",
    "        data = preprocessWR(pd.read_excel(str(year) + \"NFLData.xlsx\"))\n",
    "        yearToOriginalData[year] = copy.deepcopy(data)\n",
    "        if(index != 0):\n",
    "            for name in data.index: \n",
    "                if name in yearToOriginalData[year + 1][\"FantPt\"]:\n",
    "                    data[\"FantPt\"][name] = yearToOriginalData[year + 1][\"FantPt\"][name]\n",
    "                else:\n",
    "                    data = data.drop(name)\n",
    "            data.index = data.index.map(lambda name: name + str(year))\n",
    "            if(finalData.empty):\n",
    "                finalData = data\n",
    "            else:\n",
    "                finalData = finalData.append(data)\n",
    "    finalData = finalData.astype(int)\n",
    "    return (finalData, yearToOriginalData[2018])\n",
    "def normalizeData(data, train_data_stats):\n",
    "    return (data - train_data_stats['mean'])/train_data_stats['std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1                    Age   G  Tgt  Rec   Yds  TD  FantPt\n",
      "Player                                                  \n",
      "DeAndre Hopkins2017   25  15  174   96  1378  13     219\n",
      "Antonio Brown2017     29  14  163  101  1533   9     220\n",
      "Keenan Allen2017      25  16  159  102  1393   6     163\n",
      "Tyreek Hill2017       23  15  105   75  1183   7     247\n",
      "Julio Jones2017       28  16  148   88  1444   3     213\n",
      "...                  ...  ..  ...  ...   ...  ..     ...\n",
      "Markus Wheaton2013    22  12   13    6    64   0      78\n",
      "Denard Robinson2013   23  16    1    0     0   0      91\n",
      "Brandon Tate2013      26  16    2    1     6   0      25\n",
      "Eric Weems2013        28  16    2    1     8   0      22\n",
      "Damaris Johnson2013   24  13    3    2    14   0      41\n",
      "\n",
      "[397 rows x 7 columns]\n",
      "1               Age   G  Tgt  Rec   Yds  TD\n",
      "Player                                     \n",
      "Tyreek Hill      24  16  137   87  1479  12\n",
      "Antonio Brown    30  15  168  104  1297  15\n",
      "Davante Adams    26  15  169  111  1386  13\n",
      "DeAndre Hopkins  26  16  163  115  1572  11\n",
      "Julio Jones      29  16  170  113  1677   8\n",
      "...              ..  ..  ...  ...   ...  ..\n",
      "Sammie Coates    25  12    2    1    12   0\n",
      "Justin Hardee    24  16    1    1    10   0\n",
      "Marcus Kemp      23  16    2    1     7   0\n",
      "Justin Watson    23  12    3    1     5   0\n",
      "J'Mon Moore      23  12    3    2    15   0\n",
      "\n",
      "[128 rows x 6 columns]\n",
      "1             Age           G         Tgt         Rec          Yds  \\\n",
      "count  397.000000  397.000000  397.000000  397.000000   397.000000   \n",
      "mean    25.748111   15.209068   80.967254   48.909320   644.876574   \n",
      "std      2.882729    1.222317   46.468154   29.956481   411.315999   \n",
      "min     21.000000   12.000000    1.000000    0.000000     0.000000   \n",
      "25%     24.000000   15.000000   43.000000   23.000000   300.000000   \n",
      "50%     25.000000   16.000000   79.000000   48.000000   613.000000   \n",
      "75%     28.000000   16.000000  114.000000   69.000000   941.000000   \n",
      "max     35.000000   16.000000  203.000000  136.000000  1871.000000   \n",
      "\n",
      "1              TD      FantPt  \n",
      "count  397.000000  397.000000  \n",
      "mean     4.052897   89.282116  \n",
      "std      3.282910   57.166477  \n",
      "min      0.000000   -1.000000  \n",
      "25%      2.000000   44.000000  \n",
      "50%      3.000000   83.000000  \n",
      "75%      6.000000  126.000000  \n",
      "max     14.000000  252.000000  \n"
     ]
    }
   ],
   "source": [
    "years = reversed(range(2013,2019))\n",
    "final_data, currentYearData = createDataset(years)\n",
    "currentYearData.pop(\"FantPt\")\n",
    "print(final_data)\n",
    "print(currentYearData)\n",
    "print(final_data.astype(int).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_labels = final_data.pop(\"FantPt\")\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(final_data, final_labels, test_size = 0.2)\n",
    "normalized_train_data = normalizeData(train_data, train_data.astype(int).describe().transpose())\n",
    "normalized_test_data = normalizeData(test_data, train_data.astype(int).describe().transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_160 (Dense)            (None, 128)               896       \n",
      "_________________________________________________________________\n",
      "dense_161 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_162 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_163 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_164 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 165,761\n",
      "Trainable params: 165,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(128, activation=tf.nn.relu, input_shape=[len(train_data.keys())]),\n",
    "    layers.Dense(256, activation=tf.nn.relu),\n",
    "    layers.Dense(256, activation=tf.nn.relu),\n",
    "    layers.Dense(256, activation=tf.nn.relu),\n",
    "    layers.Dense(1, activation='linear')\n",
    "  ])\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "            optimizer= 'adam',\n",
    "            metrics=['mean_absolute_error', 'mean_squared_error'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_mean_absolute_error</th>\n",
       "      <th>val_mean_squared_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1333.139703</td>\n",
       "      <td>29.280092</td>\n",
       "      <td>1333.139648</td>\n",
       "      <td>1783.563049</td>\n",
       "      <td>34.364735</td>\n",
       "      <td>1783.562988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1315.631075</td>\n",
       "      <td>29.237823</td>\n",
       "      <td>1315.631104</td>\n",
       "      <td>1768.181091</td>\n",
       "      <td>33.680370</td>\n",
       "      <td>1768.181152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1462.647794</td>\n",
       "      <td>30.147305</td>\n",
       "      <td>1462.647827</td>\n",
       "      <td>1910.614075</td>\n",
       "      <td>36.057884</td>\n",
       "      <td>1910.614014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1409.554164</td>\n",
       "      <td>30.523472</td>\n",
       "      <td>1409.554077</td>\n",
       "      <td>1786.631165</td>\n",
       "      <td>33.575336</td>\n",
       "      <td>1786.631104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1352.111563</td>\n",
       "      <td>29.296896</td>\n",
       "      <td>1352.111572</td>\n",
       "      <td>1815.119995</td>\n",
       "      <td>35.172989</td>\n",
       "      <td>1815.119995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           loss  mean_absolute_error  mean_squared_error     val_loss  \\\n",
       "27  1333.139703            29.280092         1333.139648  1783.563049   \n",
       "28  1315.631075            29.237823         1315.631104  1768.181091   \n",
       "29  1462.647794            30.147305         1462.647827  1910.614075   \n",
       "30  1409.554164            30.523472         1409.554077  1786.631165   \n",
       "31  1352.111563            29.296896         1352.111572  1815.119995   \n",
       "\n",
       "    val_mean_absolute_error  val_mean_squared_error  \n",
       "27                34.364735             1783.562988  \n",
       "28                33.680370             1768.181152  \n",
       "29                36.057884             1910.614014  \n",
       "30                33.575336             1786.631104  \n",
       "31                35.172989             1815.119995  "
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "history = model.fit(normalized_train_data, train_labels, epochs=1000,\n",
    "                    validation_split = 0.2, verbose=0, batch_size = 32, callbacks=[early_stop])\n",
    "hist = pd.DataFrame(history.history)\n",
    "hist.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 30.947368621826172 Fantasy Points\n"
     ]
    }
   ],
   "source": [
    "loss, mae, mse = model.evaluate(normalized_test_data, test_labels, verbose=0)\n",
    "print(f'Mean Absolute Error: {mae} Fantasy Points')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "currentSeasonPredictions = model.predict(normalizeData(currentYearData, train_data.astype(int).describe().transpose())).flatten()\n",
    "playerToPrediction = pd.DataFrame()\n",
    "playerToPrediction['Player'] = currentYearData.index\n",
    "playerToPrediction['Projected Fantasy Points'] = currentSeasonPredictions\n",
    "playerToPrediction = playerToPrediction.sort_values(by='Projected Fantasy Points', ascending = False)\n",
    "playerToPrediction = playerToPrediction.set_index(\"Player\")\n",
    "playerToPrediction.to_excel(\"WRFantasyPredictions2019v2.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testenv",
   "language": "python",
   "name": "testenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
